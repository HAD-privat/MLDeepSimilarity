{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "#print('Tesorflow version: ' ,tf.__version__)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "# Hyperparmeters Model Training\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "margin = 1\n",
    "\n",
    "# Path\n",
    "home = Path.home()\n",
    "PATH_LIB = Path(home, 'repositories','MLDeepSimilarity','MLDeepSimilarity','Data','Fe-PMI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PMI-Library e.g. Fe-Matrix\n",
    "df= pd.read_excel(PATH_LIB)\n",
    "df.rename(columns={'Material Name': 'Label'}, inplace=True, errors='raise')    # unify header dataframes\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create values and label list from df\n",
    "def create_lists_values_labels(df):\n",
    "    df_labels = df['Label']\n",
    "    labels = df_labels.values.tolist()\n",
    "    df_values = df.drop(['Label'], axis=1)\n",
    "    values = df_values.values.tolist()\n",
    "    values = np.array(values) \n",
    "    return values, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buid Pairs positiv and negativ\n",
    "# The third parameter: min_equals. indicate how many equal pairs, as minimun, we want in the dataset. \n",
    "# If we just created random pairs the number of equal pairs would be very small. \n",
    "def create_pairs(x, y, min_equals = 600): # counts of full data set is 684 items\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    equal_items = 0\n",
    "    l = len(y)\n",
    "    label = list(range(l))\n",
    "    while equal_items < min_equals:\n",
    "            for i in range(0, l):\n",
    "                k = random.choice(label)\n",
    "                if i == k:\n",
    "                    equal_items += 1\n",
    "                    a = x[i]\n",
    "                    b = x[k]\n",
    "                    pairs.append([a,b])\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    a = x[i]\n",
    "                    b = x[k]\n",
    "                    pairs.append([a,b])\n",
    "                    labels.append(1)\n",
    "    return np.array(pairs).astype('float'), np.array(labels).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = np.array([])\n",
    "x_train_2 = np.array([])\n",
    "x_val_1 = np.array([])\n",
    "x_val_2 = np.array([])\n",
    "labels_train = np.array([])\n",
    "labels_val = np.array([])\n",
    "\n",
    "x,y = create_lists_values_labels(df)\n",
    "pairs, labels = create_pairs(x,y,600)\n",
    "count = int(len(labels)/2)\n",
    "\n",
    "train_i1 = [] \n",
    "train_i2 = []\n",
    "for i in pairs:\n",
    "   train_i1.append(i[0])\n",
    "   train_i2.append(i[1])\n",
    "x_test_1 = np.array(train_i1[0:1])\n",
    "x_test_2 = np.array(train_i1[0:1])\n",
    "x_train_1 = np.array(train_i1[100:count])\n",
    "x_train_2 = np.array(train_i2[100:count])\n",
    "x_val_1 = np.array(train_i2[count+1::])\n",
    "x_val_2 = np.array(train_i2[count+1::])\n",
    "labels_test = np.array(labels[0:1])\n",
    "labels_train = np.array(labels[100:count])\n",
    "labels_val = np.array(labels[count+1::])\n",
    "\n",
    "print(x_test_2)\n",
    "print(x_test_1)\n",
    "print(x_train_1.shape)\n",
    "print(x_train_2.shape)\n",
    "print(x_val_1.shape)\n",
    "print(x_val_2.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(vects):\n",
    "    x,y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x-y),axis=1,keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.minimum(sum_square,tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    \n",
    "    def contrative_loss(y_true,y_pred):\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "    return contrative_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Siamese Network\n",
    "input = tf.keras.layers.Input(40,)\n",
    "#normal_layer = tf.keras.layers.BatchNormalization()(input)\n",
    "x = tf.keras.layers.Dense(40, activation='relu')(input)\n",
    "x = tf.keras.layers.Dense(40, activation='relu',name='First',dtype=float)(x)\n",
    "embedding_network = tf.keras.Model(input,x)\n",
    "\n",
    "input_a = tf.keras.layers.Input(40,)\n",
    "input_b = tf.keras.layers.Input(40,)\n",
    "\n",
    "embedding_a = embedding_network(input_a)\n",
    "embedding_b = embedding_network(input_b)\n",
    "\n",
    "merge_layer = tf.keras.layers.Lambda(euclidian_distance)([embedding_a,embedding_b])\n",
    "#normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = tf.keras.layers.Dense(1,activation='sigmoid')(merge_layer)\n",
    "siamese_network = tf.keras.Model(inputs=[input_a,input_b],outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#siamese_network.compile(loss=loss(margin=margin), optimizer='RMSprop', metrics=[\"accuracy\"])\n",
    "siamese_network.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),metrics=['accuracy'])\n",
    "history = siamese_network.fit([x_train_1, x_train_2],labels_train,validation_data=([x_val_1, x_val_2],labels_val),batch_size=batch_size,epochs=epochs,)\n",
    "print(siamese_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_metric(history, metric, title, has_valid=True):\n",
    "    \"\"\"Plots the given 'metric' from 'history'.\n",
    "\n",
    "    Arguments:\n",
    "        history: history attribute of History object returned from Model.fit.\n",
    "        metric: Metric to plot, a string value present as key in 'history'.\n",
    "        title: A string to be used as title of plot.\n",
    "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.plot(history[metric])\n",
    "    if has_valid:\n",
    "        plt.plot(history[\"val_\" + metric])\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot the accuracy\n",
    "plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")\n",
    "\n",
    "# Plot the constrastive loss\n",
    "plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = siamese_network.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "predictions = siamese_network.predict([x_test_1,x_test_2])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf786bf6bd8749fda03ad2b92b03ec79d486b3dd71d74ee5e9cf9f82b1c5f48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
